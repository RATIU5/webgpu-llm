<SYSTEM>Workgroup Variables and Shared Memory: Using workgroup-scoped variables for inter-thread communication</SYSTEM>

# Workgroup Variables and Shared Memory

## Overview [Section titled “Overview”](#overview) Workgroup variables provide fast on-chip shared memory accessible by all threads in a workgroup. This memory is 10-20× faster than global storage buffers, enabling efficient parallel algorithms. ## When to Use Workgroup Memory [Section titled “When to Use Workgroup Memory”](#when-to-use-workgroup-memory) | Use Case | Benefit | | -------------------- | ----------------------------------------- | | Data reuse | Load once, read many times | | Intermediate results | Share values between threads | | Parallel reduction | Sum/max/min across threads | | Tiled algorithms | Matrix multiplication, convolutions | | Cooperative caching | Cache global data for neighborhood access | ## WGSL Declaration [Section titled “WGSL Declaration”](#wgsl-declaration) Workgroup variable declarations ```wgsl var<workgroup> sharedData: array<f32, 256>; var<workgroup> tileCache: array<vec4f, 64>; var<workgroup> hitCount: atomic<u32>; ``` Compute Shaders Only Workgroup variables are only available in compute shaders—vertex and fragment shaders don’t have workgroups. ### Size Planning [Section titled “Size Planning”](#size-planning) Memory budget calculation ```wgsl var<workgroup> cache: array<f32, 256>; // 256 × 4 = 1,024 bytes var<workgroup> positions: array<vec4f, 128>; // 128 × 16 = 2,048 bytes var<workgroup> indices: array<u32, 512>; // 512 × 4 = 2,048 bytes // Total: 5,120 bytes (within 16KB limit) ``` Query device limits: Check available workgroup storage ```javascript console.log("Max storage:", device.limits.maxComputeWorkgroupStorageSize); ``` ## TypeGPU Declaration [Section titled “TypeGPU Declaration”](#typegpu-declaration) TypeGPU workgroup variables ```typescript import tgpu from "typegpu"; import * as d from "typegpu/data"; const sharedData = tgpu.workgroupVar(d.arrayOf(d.f32, 256)); const sharedVectors = tgpu.workgroupVar(d.arrayOf(d.vec4f, 128)); const ParticleData = d.struct({ position: d.vec3f, velocity: d.vec3f, }); const sharedParticles = tgpu.workgroupVar(d.arrayOf(ParticleData, 64)); ``` ## Synchronization [Section titled “Synchronization”](#synchronization) ### workgroupBarrier() [Section titled “workgroupBarrier()”](#workgroupbarrier) All threads must reach the barrier before any can proceed. Also ensures memory visibility. Barrier usage ```wgsl var<workgroup> sharedData: array<f32, 256>; @compute @workgroup_size(256) fn computeMain(@builtin(local_invocation_index) idx: u32) { // Phase 1: Each thread writes sharedData[idx] = f32(idx) * 2.0; workgroupBarrier(); // Wait for all writes // Phase 2: Safe to read other threads' data let neighbor = sharedData[(idx + 1u) % 256u]; } ``` Always Synchronize Without barriers, threads may read before others have written: ```wgsl // BUG: Race condition! sharedData[idx] = f32(idx); let value = sharedData[(idx + 1u) % 256u]; // May read garbage! ``` ### storageBarrier() [Section titled “storageBarrier()”](#storagebarrier) Synchronizes storage buffer and atomic operations (but NOT execution): Storage barrier ```wgsl atomicAdd(&globalCounter, 1u); storageBarrier(); // Ensure atomic completes output[gid.x] = f32(value); ``` ## Common Patterns [Section titled “Common Patterns”](#common-patterns) ## Performance Considerations [Section titled “Performance Considerations”](#performance-considerations) ### Bank Conflicts [Section titled “Bank Conflicts”](#bank-conflicts) Workgroup memory uses banks—simultaneous access to the same bank serializes: Avoid bank conflicts ```wgsl // BAD: All threads access same element let value = sharedData[0]; // Serialized! // GOOD: Each thread accesses different element let value = sharedData[idx]; // Parallel! ``` ### Optimal Access Patterns [Section titled “Optimal Access Patterns”](#optimal-access-patterns) | Pattern | Performance | | ---------------------- | ---------------- | | Sequential access | Fast | | Broadcast (same value) | Fast | | Random access | Medium | | Strided (every 32nd) | Slow (conflicts) | ### Workgroup Size [Section titled “Workgroup Size”](#workgroup-size) ## Platform Limits [Section titled “Platform Limits”](#platform-limits) | Platform | Typical Limit | | ----------------- | ------------- | | Desktop NVIDIA | 48KB | | Desktop AMD/Intel | 32KB | | Mobile | 16-32KB | | WebGPU Minimum | 16KB | ## Common Pitfalls [Section titled “Common Pitfalls”](#common-pitfalls) Missing Barrier ```wgsl sharedData[idx] = f32(idx); // Missing workgroupBarrier()! let value = sharedData[(idx + 1u) % 256u]; // Race condition! ``` Race Condition with Non-Atomic ```wgsl // WRONG: Use atomic<u32> for shared counters var<workgroup> counter: u32; counter += 1u; // Race condition! // CORRECT var<workgroup> counter: atomic<u32>; atomicAdd(&counter, 1u); ``` Exceeding Size Limit ```wgsl // May fail on some devices (32KB) var<workgroup> huge: array<vec4f, 2048>; // 2048 × 16 = 32KB ``` Reading Uninitialized Data Workgroup memory starts uninitialized. Always write before reading: ```wgsl // BUG: Only thread 0 writes, others read garbage if (idx == 0u) { sharedData[0] = 42.0; } workgroupBarrier(); let value = sharedData[idx]; // data[1..255] uninitialized! ``` ## Resources [Section titled “Resources”](#resources)